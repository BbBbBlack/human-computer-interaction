{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mD:\\anaconda\\lib\\importlib\\_bootstrap_external.py\u001b[0m in \u001b[0;36m_path_is_mode_type\u001b[1;34m(path, mode)\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\importlib\\_bootstrap_external.py\u001b[0m in \u001b[0;36m_path_stat\u001b[1;34m(path)\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] 系统找不到指定的文件。: 'D:\\\\anaconda\\\\lib\\\\site-packages\\\\tensorflow\\\\core\\\\profiler\\\\__init__.cp36-win_amd64.pyd'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-64156d691fe5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\tensorflow\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;31m# pylint: disable=g-bad-import-order\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpywrap_tensorflow\u001b[0m  \u001b[1;31m# pylint: disable=unused-import\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\tensorflow\\python\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinalg\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlinalg\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlosses\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlosses\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 94\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprofiler\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mprofiler\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     95\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msaved_model\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msaved_model\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msummary\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\tensorflow\\python\\profiler\\profiler.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;31m# pylint: disable=unused-import\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtfprof_log_pb2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mOpLogProto\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtfprof_output_pb2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mAdviceProto\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtfprof_output_pb2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mGraphNodeProto\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_find_spec\u001b[1;34m(name, path, target)\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\importlib\\_bootstrap_external.py\u001b[0m in \u001b[0;36mfind_spec\u001b[1;34m(cls, fullname, path, target)\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\importlib\\_bootstrap_external.py\u001b[0m in \u001b[0;36m_get_spec\u001b[1;34m(cls, fullname, path, target)\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\importlib\\_bootstrap_external.py\u001b[0m in \u001b[0;36mfind_spec\u001b[1;34m(self, fullname, target)\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\importlib\\_bootstrap_external.py\u001b[0m in \u001b[0;36m_path_isfile\u001b[1;34m(path)\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\importlib\\_bootstrap_external.py\u001b[0m in \u001b[0;36m_path_is_mode_type\u001b[1;34m(path, mode)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "'''keywords = ['blink','event','fixation','PD','pupil','saccade']\n",
    "dataset_path = dict()\n",
    "dataset = dict()\n",
    "for k in keywords:\n",
    "    dataset_path[k] = \"D:/Downloads/SEED_IV/eye_raw_data/\"+\"huan_20150915_\"+k+\".mat\"\n",
    "    temp = sio.loadmat(dataset_path[k])\n",
    "    for x in temp:\n",
    "        if isinstance(temp[x],np.ndarray):\n",
    "            dataset[k] = temp[x] \n",
    "\n",
    "\n",
    "print('blink: ',dataset['blink'][1,0].shape)   # \n",
    "print('event: ',dataset['event'][1,0].shape)   # \n",
    "print('fixation: ',dataset['fixation'][1,0].shape)   # \n",
    "print('sum: ', np.sum(dataset['fixation'][0,0], axis=0))\n",
    "print('pupil: ',dataset['pupil'][1,0][:10])      # \n",
    "print('PD: ',dataset['PD'][1,0].shape)         # pupil diameter\n",
    "print('saccade: ',dataset['saccade'][1,0].shape)    '''     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''import os\n",
    "dataset_dir\t\t=   \"./data_preprocessed_matlab/\"\n",
    "window_size\t\t=\t128\n",
    "output_dir\t\t=   \"./eye/\"\n",
    "# get directory name for one subject\n",
    "record_list = [task for task in os.listdir(dataset_dir) if os.path.isfile(os.path.join(dataset_dir,task))]\n",
    "eye_data = []\n",
    "label_data = []\n",
    "for record in record_list:\n",
    "    file = os.path.join(dataset_dir,record)\n",
    "    print(file)\n",
    "    data = sio.loadmat(file)['data']\n",
    "    labels = sio.loadmat(file)['labels']\n",
    "    eye_data.append(data[:,32:34,:])\n",
    "    label_data.append(labels)\n",
    "eye_data = np.array(eye_data)\n",
    "label_data = np.array(label_data)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def windows(data, size):\n",
    "    start = 0\n",
    "    while ((start+size) < data.shape[0]):\n",
    "        yield int(start), int(start + size)\n",
    "        start += size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_signal_without_transition(data,label,label_index,window_size):\n",
    "    # get data file name and label file name\n",
    "    for (start, end) in windows(data, window_size):\n",
    "        if((len(data[start:end]) == window_size)):\n",
    "            if(start == 0):\n",
    "                segments = data[start:end]\n",
    "                segments = np.vstack([segments, data[start:end]])\n",
    "                \n",
    "                labels = np.array(label[label_index])\n",
    "                labels = np.append(labels, np.array(label[label_index]))\n",
    "            else:\n",
    "                segments = np.vstack([segments, data[start:end]])\n",
    "                labels = np.append(labels, np.array(label[label_index])) # labels = np.append(labels, stats.mode(label[start:end])[0][0])\n",
    "    return segments, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对一维特征进行特征标准化\n",
    "def feature_normalize(data):\n",
    "    # 计算样本均值\n",
    "    mean = data[data.nonzero()].mean()\n",
    "    # 计算样本标准差\n",
    "    sigma = data[data. nonzero ()].std()\n",
    "    data_normalized = data\n",
    "    data_normalized[data_normalized.nonzero()] = (data_normalized[data_normalized.nonzero()] - mean)/sigma\n",
    "    # return shape: 9*9\n",
    "    return data_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import time\n",
    "begin = time.time()\n",
    "print(\"time begin:\",time.localtime())\n",
    "window_size = 128\n",
    "output_dir\t\t=   \"../preprocesseddata/\"\n",
    "suffix          =   'no'     # yes/no (using baseline signals or not)\n",
    "output_dir = output_dir+suffix+\"_\"+\"/\"\n",
    "if os.path.isdir(output_dir)==False:\n",
    "    os.makedirs(output_dir)\n",
    "eye_data = eye_data.transpose(0,1,3,2)\n",
    "eye_data_aft_proc = np.zeros(shape=[eye_data.shape[0],eye_data.shape[1],60,window_size,eye_data.shape[-1]])\n",
    "for person in range(32):\n",
    "    # label只选择arousal\n",
    "    L = label_data[person,:,0].reshape(-1,1)\n",
    "    ed = eye_data[person]\n",
    "    for i,video in enumerate(ed):\n",
    "        # 不用base,去掉前三个mj  \n",
    "        video_h = video[3 * 128:,0]\n",
    "        video_v = video[3 * 128:,1]\n",
    "        video_h = feature_normalize(video_h)\n",
    "        video_v = feature_normalize(video_v)\n",
    "        video_h, L = segment_signal_without_transition(video_h,L,i,window_size)\n",
    "        video_v, L = segment_signal_without_transition(video_v,L,i,window_size)\n",
    "        index = np.array(range(video_h.shape[0]))\n",
    "        np.random.shuffle(index)\n",
    "        video_h = video_h[index]\n",
    "        video_v = video_v[index]\n",
    "        eye_data_aft_proc[person,i,:,:,0] = video_h\n",
    "        eye_data_aft_proc[person,i,:,:,1] = video_v\n",
    "print(eye_data_aft_proc.shape)\n",
    "for i in range(32):\n",
    "    output_file = output_dir+\"AFT_PREPROCESS_\"+str(i+1)+\"_DATASET.pkl\"\n",
    "    output_label = output_dir+\"AFT_PREPROCESS_\"+str(i+1)+\"_LABELSET.pkl\"\n",
    "    with open(output_file, \"wb\") as fp:\n",
    "        pickle.dump(eye_data_aft_proc[i] ,fp, protocol=4)\n",
    "    with open(output_label, \"wb\") as fp:\n",
    "        pickle.dump(label_data[i], fp, protocol=4)\n",
    "    end = time.time()\n",
    "    print(\"end time:\",time.localtime())\n",
    "    print(\"time consuming:\",(end-begin))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 0 0 0]\n",
      " [0 1 0 0 0]\n",
      " [0 0 0 1 0]\n",
      " [0 0 1 0 0]\n",
      " [0 0 0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "labels = np.array([1,2,4,3,5])\n",
    "labels = list(labels)\n",
    "one_hot_labels = np.array(list(pd.get_dummies(labels)))\n",
    "labels = np.asarray(pd.get_dummies(labels), dtype=np.int8)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([1,2,3,4,5]).reshape(5,1)\n",
    "a.flatten()\n",
    "print(a.shape)\n",
    "[x for x in a[:,0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

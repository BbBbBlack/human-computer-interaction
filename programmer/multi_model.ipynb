{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from keras import Sequential,backend,optimizers\n",
    "from keras.layers import Dense,Input, Activation, Flatten, Convolution2D, Dropout,Reshape,LSTM,concatenate,SeparableConv2D\n",
    "from keras.models import Model\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "list1=[]\n",
    "#list1=os.listdir('no_eog')\n",
    "print(list1)\n",
    "list2=os.listdir('yes_arousal_old')\n",
    "print(list2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for i in list2:\n",
    "    if(re.search(\"cnn\",i)):\n",
    "        with open(\"sample/\"+i,\"rb\") as f:\n",
    "            cnn_dataset = pickle.load(f)\n",
    "            print(cnn_dataset.shape)\n",
    "            if(i=='s01.mat_win_128_cnn_dataset.pkl'):\n",
    "                cnn_datasets=cnn_dataset\n",
    "                print(1)\n",
    "            else:\n",
    "                cnn_datasets=np.concatenate((cnn_datasets,cnn_dataset),axis=0)\n",
    "                #cnn_datasets=np.append(cnn_datasets, cnn_dataset, axis=0)\n",
    "    elif(re.search(\"rnn\",i)):\n",
    "        with open(\"sample/\"+i,\"rb\") as f:\n",
    "            rnn_dataset = pickle.load(f)\n",
    "            print(rnn_dataset.shape)\n",
    "            if(i=='s01.mat_win_128_rnn_dataset.pkl'):\n",
    "                rnn_datasets=rnn_dataset\n",
    "                print(1)\n",
    "            else:\n",
    "                rnn_datasets=np.concatenate((rnn_datasets,cnn_dataset),axis=0)\n",
    "                #rnn_datasets=np.append(rnn_datasets, rnn_dataset, axis=0)\n",
    "    elif(re.search(\"labels\",i)):\n",
    "        with open(\"sample/\"+i,\"rb\") as f:\n",
    "            label = pickle.load(f) \n",
    "            print(label.shape)\n",
    "            if(i=='s01.mat_win_128_labels.pkl'):\n",
    "                print(label.shape)\n",
    "                labels=label\n",
    "                print(1)\n",
    "            else:\n",
    "                labels=np.concatenate((labels,label),axis=0)\n",
    "                #labels=np.append(labels, label, axis=0)\n",
    "for i in list1:\n",
    "    with open('no_eog/'+i,\"rb\") as f:\n",
    "        eog=pickle.load(f)\n",
    "        eog=np.reshape(eog,(-1,128,2))\n",
    "        print(eog.shape)\n",
    "        if(i=='AFT_PREPROCESS_1_DATASET.pkl'):\n",
    "            eog_dataset=eog\n",
    "            print(1)\n",
    "        else:\n",
    "            eog_datasets=np.concatenate((eog_datasets,eog),axis=0)\n",
    "            eog_dataset=np.append(eog_dataset,eog,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "L=2\n",
    "cnn_datasets=np.empty(shape=[0,128,9,9])\n",
    "rnn_datasets=np.empty(shape=[0,128,32])\n",
    "labels=np.empty(shape=[0,])\n",
    "eog_datasets=np.empty(shape=[0,128,2])\n",
    "for i in range(1,L+1):\n",
    "    with open('../preprocessed_data/s0'+str(i)+'.mat_win_128_cnn_dataset.pkl',\"rb\") as f:\n",
    "        cnn_dataset = pickle.load(f)\n",
    "    with open('../preprocessed_data/s0'+str(i)+'.mat_win_128_labels.pkl',\"rb\") as f:\n",
    "        label = pickle.load(f)   \n",
    "    with open('../preprocessed_data/s0'+str(i)+'.mat_win_128_rnn_dataset.pkl',\"rb\") as f:\n",
    "        rnn_dataset = pickle.load(f) \n",
    "    with open('../preprocessed_data/AFT_PREPROCESS_'+str(i)+'_DATASET.pkl',\"rb\") as f:\n",
    "        eog = pickle.load(f) \n",
    "        eog=np.reshape(eog,(-1,128,2))\n",
    "    cnn_datasets=np.concatenate((cnn_datasets,cnn_dataset),axis=0)\n",
    "    rnn_datasets=np.concatenate((rnn_datasets,rnn_dataset),axis=0)\n",
    "    labels=np.concatenate((labels,label),axis=0)\n",
    "    eog_datasets=np.concatenate((eog_datasets,eog),axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with open('D:\\learn\\human-machine interaction\\yes_arousal_old/s01.mat_win_128_cnn_dataset.pkl',\"rb\") as f:\n",
    "    cnn_datasets = pickle.load(f)\n",
    "with open('D:\\learn\\human-machine interaction\\yes_arousal_old/s01.mat_win_128_labels.pkl',\"rb\") as f:\n",
    "    labels = pickle.load(f)   \n",
    "with open('D:\\learn\\human-machine interaction\\yes_arousal_old/s01.mat_win_128_rnn_dataset.pkl',\"rb\") as f:\n",
    "    rnn_datasets = pickle.load(f) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4800, 128, 9, 9)\n",
      "(4800,)\n",
      "(4800, 128, 32)\n",
      "(4800, 128, 2)\n",
      "(4800, 128, 34)\n"
     ]
    }
   ],
   "source": [
    "print(cnn_datasets.shape)\n",
    "print(labels.shape)\n",
    "print(rnn_datasets.shape)\n",
    "print(eog_datasets.shape)\n",
    "lstm_datasets=rnn_datasets\n",
    "lstm_datasets=np.concatenate((rnn_datasets,eog_datasets),axis=2)\n",
    "print(lstm_datasets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_datasets=np.transpose(cnn_datasets, [0,2,3,1])\n",
    "#cnn_datasets = cnn_datasets.transpose(0,2,3,1)\n",
    "lstm_datasets=np.transpose(lstm_datasets, [0,2,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4800, 9, 9, 128)\n",
      "(4800,)\n",
      "(4800, 34, 128)\n"
     ]
    }
   ],
   "source": [
    "print(cnn_datasets.shape)\n",
    "print(labels.shape)\n",
    "print(lstm_datasets.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## shuffle data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels shape after shuffle: (4800,)\n",
      "cnn_datasets shape after shuffle: (4800, 9, 9, 128)\n",
      "lstm_datasets shape after shurffle:(4800, 34, 128)\n"
     ]
    }
   ],
   "source": [
    "permutation = np.random.permutation(labels.shape[0])\n",
    "#shuffled_dataset = labels[permutation, :]\n",
    "labels = labels[permutation]\n",
    "cnn_datasets = cnn_datasets[permutation]\n",
    "lstm_datasets = lstm_datasets[permutation]\n",
    "print(\"labels shape after shuffle: {0}\\ncnn_datasets shape after shuffle: {1}\\nlstm_datasets shape after shurffle:{2}\"\\\n",
    "      .format(labels.shape, cnn_datasets.shape, lstm_datasets.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_labels = np.array(list(pd.get_dummies(labels)))\n",
    "labels = np.asarray(pd.get_dummies(labels), dtype=np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'int'>\n",
      "(3840, 9, 9, 128)\n",
      "(3840, 34, 128)\n",
      "(3840, 2)\n"
     ]
    }
   ],
   "source": [
    "L=cnn_datasets.shape[0]\n",
    "print(type(L))\n",
    "L=int(0.8*L)\n",
    "cnn_train=cnn_datasets[:L,:,:,:]\n",
    "cnn_test=cnn_datasets[L:,:,:,:]\n",
    "lstm_train=lstm_datasets[:L,:,:]\n",
    "lstm_test=lstm_datasets[L:,:,:]\n",
    "labels_train=labels[:L,]\n",
    "labels_test=labels[L:,]\n",
    "print(cnn_train.shape)\n",
    "print(lstm_train.shape)\n",
    "print(labels_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "cnn_input (InputLayer)          (None, 9, 9, 128)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_1 (SeparableCo (None, 9, 9, 32)     6176        cnn_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 9, 9, 64)     32832       separable_conv2d_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "lstm_input (InputLayer)         (None, 34, 128)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 9, 9, 128)    131200      conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 34, 1024)     132096      lstm_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 9, 9, 13)     1677        conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 34, 32)       135296      dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 1053)         0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   (None, 32)           8320        lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 1085)         0           flatten_1[0][0]                  \n",
      "                                                                 lstm_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 2)            2172        concatenate_1[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 449,769\n",
      "Trainable params: 449,769\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn_input=Input(shape=(9,9,128), name='cnn_input') #cnn_input\n",
    "cnn_1=SeparableConv2D(32,(4,4),strides=(1,1),\n",
    "               activation='elu'\n",
    "               ,padding='SAME'\n",
    "               )(cnn_input)\n",
    "cnn_2=Convolution2D(64,(4,4),strides=(1,1),\n",
    "               activation='elu'\n",
    "               ,padding='SAME'\n",
    "               )(cnn_1)\n",
    "cnn_3=Convolution2D(128,(4,4),strides=(1,1),\n",
    "               activation='elu'\n",
    "               ,padding='SAME'\n",
    "               )(cnn_2)\n",
    "cnn_4=Convolution2D(13,(1,1),strides=(1,1),\n",
    "               activation='elu',padding='SAME'\n",
    "                )(cnn_3)\n",
    "cnn_output=Flatten()(cnn_4)\n",
    "lstm_input=Input(shape=(34,128),name='lstm_input') #lstm_input\n",
    "dense=Dense(1024,input_shape=(34,128))(lstm_input)\n",
    "lstm_1=LSTM(32,input_shape=(32, 1024),return_sequences=True)(dense)\n",
    "lstm_2=LSTM(32)(lstm_1)\n",
    "x = concatenate([cnn_output,lstm_2],axis=-1)\n",
    "#output_2=Flatten()(output_1)\n",
    "output=Dense(2,activation='softmax')(x) #output\n",
    "model = Model(inputs=[cnn_input, lstm_input], outputs=[output])\n",
    "#print(type(model))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer=optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3840 samples, validate on 960 samples\n",
      "Epoch 1/5\n",
      "5/5 [==============================] - 107s 21s/step - loss: 0.5830 - acc: 0.7039 - val_loss: 0.4830 - val_acc: 0.7906\n",
      "Epoch 2/5\n",
      "5/5 [==============================] - 97s 19s/step - loss: 0.4059 - acc: 0.8328 - val_loss: 0.3463 - val_acc: 0.8615\n",
      "Epoch 3/5\n",
      "5/5 [==============================] - 94s 19s/step - loss: 0.2823 - acc: 0.8889 - val_loss: 0.2530 - val_acc: 0.8969\n",
      "Epoch 4/5\n",
      "5/5 [==============================] - 98s 20s/step - loss: 0.1924 - acc: 0.9269 - val_loss: 0.1935 - val_acc: 0.9292\n",
      "Epoch 5/5\n",
      "4/5 [=======================>......] - ETA: 17s - loss: 0.1327 - acc: 0.9537"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-a5c24a265006>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m history = model.fit([cnn_train,lstm_train],[labels_train],epochs=5,steps_per_epoch = 5,validation_data=([cnn_test,lstm_test],[labels_test]),\n\u001b[1;32m----> 2\u001b[1;33m                     \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m                 )\n\u001b[0;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'my_model.h5'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    152\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'size'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    153\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 154\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    155\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    156\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1397\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1398\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1399\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1400\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1401\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit([cnn_train,lstm_train],[labels_train],epochs=5,steps_per_epoch = 5,validation_data=([cnn_test,lstm_test],[labels_test]),\n",
    "                    validation_steps=5\n",
    "                )\n",
    "model.save('my_model.h5')           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "# \"bo\" is for \"blue dot\"\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "# b is for \"solid blue line\"\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()   # clear figure\n",
    "\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
